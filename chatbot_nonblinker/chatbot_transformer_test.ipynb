{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import math\n",
    "from mecab import MeCab\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 생성 함수, 어휘 사전을 만들 때 사용\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "    cleaner = re.compile(korean_pattern)\n",
    "    text = cleaner.sub(\"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens, VOCAB):\n",
    "    if isinstance(tokens, torch.Tensor): # 토큰이 텐서인지 확인\n",
    "        tokens = tokens.cpu().numpy()\n",
    "    special_tokens = np.array([VOCAB['<SOS>'], VOCAB['<PAD>'], VOCAB['<UNK>'], VOCAB['<EOS>']])\n",
    "    tokens = [token for token in tokens if token not in special_tokens]\n",
    "    return ' '.join(VOCAB.lookup_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tokens(text):\n",
    "    return [VOCAB[token] for token in tokenizer.morphs(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 데이터셋 클래스, 질문-답변 쌍을 다룹니다.\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, pairs, vocab, tokenizer, input_seq_len, target_seq_len):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_seq_len = input_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 질문과 답변을 쌍에서 가져옵니다.\n",
    "        question, answer = self.pairs[idx]\n",
    "\n",
    "        # 토큰화하고 인코딩합니다.\n",
    "        question_tokens = text_to_tokens(question)\n",
    "        answer_tokens = text_to_tokens(answer)\n",
    "\n",
    "        # 시퀀스를 패딩합니다.\n",
    "        enc_src = self.pad_sequence(question_tokens + [self.vocab['<EOS>']], self.input_seq_len)\n",
    "        dec_src = self.pad_sequence([self.vocab['<SOS>']] + answer_tokens, self.target_seq_len)\n",
    "        trg = self.pad_sequence([self.vocab['<SOS>']] + answer_tokens + [self.vocab['<EOS>']], \n",
    "                                self.target_seq_len)\n",
    "\n",
    "        return enc_src, dec_src, trg\n",
    "\n",
    "    def pad_sequence(self, seq, max_len):\n",
    "        return F.pad(torch.LongTensor(seq), (0, max_len - len(seq)), mode='constant', \n",
    "                     value=self.vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 및 위치 임베딩 레이어\n",
    "class WordPositionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, emb_size, device):\n",
    "        super(WordPositionEmbedding, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(vocab_size, emb_size, device=device)\n",
    "\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * \n",
    "                             (-math.log(10000.0) / emb_size))\n",
    "        pos_emb = torch.zeros(max_seq_len, emb_size)\n",
    "        pos_emb[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_emb[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('position_embedding', pos_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        word_embeddings = self.word_embedding(x)\n",
    "        pos_embeddings = self.position_embedding[:x.size(1), :]\n",
    "\n",
    "        # 단어 임베딩과 위치 임베딩을 결합합니다.\n",
    "        embeddings = word_embeddings + pos_embeddings\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티-헤드 어텐션 메커니즘 클래스\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = emb_size // heads\n",
    "\n",
    "        assert self.head_dim * heads == emb_size, \"임베딩 크기는 헤드 수로 나누어 떨어져야 합니다.\"\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, emb_size)\n",
    "\n",
    "    def forward(self, values, keys, queries, mask=None):\n",
    "        batch_size = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "\n",
    "        # 임베딩을 self.heads 개의 조각으로 나눕니다.\n",
    "        values = values.reshape(batch_size, self.heads, value_len, self.head_dim)\n",
    "        keys = keys.reshape(batch_size, self.heads, key_len, self.head_dim)\n",
    "        queries = queries.reshape(batch_size, self.heads, query_len, self.head_dim)\n",
    "\n",
    "        # 선형 변환을 수행합니다.\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        # 행렬 곱셈을 위해 전치합니다.\n",
    "        keys_transposed = keys.transpose(2, 3)\n",
    "\n",
    "        # 각 헤드에 대해 쿼리와 키의 내적을 계산합니다.\n",
    "        energy = torch.matmul(queries, keys_transposed)\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        # 에너지를 키의 차원의 제곱근으로 스케일링하고 소프트맥스를 적용합니다.\n",
    "        scale = self.head_dim ** 0.5\n",
    "        attention = torch.softmax(energy / scale, dim=-1)\n",
    "\n",
    "        # 어텐션 가중치를 값에 곱합니다.\n",
    "        out = torch.matmul(attention, values)\n",
    "\n",
    "        # 모든 헤드를 하나로 연결합니다.\n",
    "        out = out.reshape(batch_size, query_len, self.heads * self.head_dim)\n",
    "\n",
    "        # 최종 선형 레이어를 적용합니다.\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 블록, 멀티-헤드 어텐션과 피드포워드 네트워크로 구성됩니다.\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_size, heads, forward_expansion, dropout_rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(emb_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(emb_size)\n",
    "        self.norm2 = nn.LayerNorm(emb_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(emb_size, forward_expansion * emb_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * emb_size, emb_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        # 어텐션과 skip connection 연결\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "\n",
    "        # 피드포워드와 skip connection 연결\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.norm2(self.dropout(forward + x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 트랜스포머 블록으로 구성된 인코더\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, emb_size, n_layers, heads, forward_expansion, \n",
    "                 drop_out, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.device = device\n",
    "        self.embedding = WordPositionEmbedding(vocab_size, seq_len, emb_size, device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(emb_size, heads, forward_expansion, drop_out) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, X, mask):\n",
    "        out = self.dropout(self.embedding(X))\n",
    "\n",
    "        # 각 트랜스포머 블록을 순차적으로 적용합니다.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 블록, 셀프 어텐션과 크로스 어텐션을 포함합니다.\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, emb_size, heads, forward_expansion, drop_out):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(emb_size, heads)\n",
    "        self.norm = nn.LayerNorm(emb_size)\n",
    "        self.transformer_block = TransformerBlock(emb_size, heads, forward_expansion, drop_out)\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, X, value, key, src_mask, trg_mask):\n",
    "        # 셀프 어텐션\n",
    "        attention = self.attention(X, X, X, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + X))\n",
    "        # 인코더 출력과의 크로스 어텐션\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 디코더 블록으로 구성된 디코더\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, emb_size, n_layers, heads, forward_expansion, \n",
    "                 drop_out, device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding = WordPositionEmbedding(vocab_size, seq_len, emb_size, device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(emb_size, heads, forward_expansion, drop_out) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(emb_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, X, enc_out, src_mask, trg_mask):\n",
    "        out = self.dropout(self.embedding(X))\n",
    "\n",
    "        # 각 디코더 블록을 처리합니다.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        # 어휘 사전으로 매핑하는 출력 레이어\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더와 디코더를 결합한 전체 트랜스포머 모델\n",
    "class TransformerScratch(nn.Module):\n",
    "    def __init__(self, inp_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, emb_size, \n",
    "                 n_layers=1, heads=1, forward_expansion=1, drop_out=0.2, max_seq_len=100, \n",
    "                 device=torch.device('cuda')):\n",
    "        super(TransformerScratch, self).__init__()\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = Encoder(inp_vocab_size, max_seq_len, emb_size, n_layers, heads, \n",
    "                               forward_expansion, drop_out, device).to(device)\n",
    "        self.decoder = Decoder(trg_vocab_size, max_seq_len, emb_size, n_layers, heads, \n",
    "                               forward_expansion, drop_out, device).to(device)\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        batch_size, trg_seq_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_seq_len, trg_seq_len))).expand(\n",
    "            batch_size, 1, trg_seq_len, trg_seq_len)\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 단일 학습 단계\n",
    "def step(model, enc_src, dec_src, trg, loss_fn, VOCAB, device):\n",
    "    enc_src = enc_src.to(device)\n",
    "    dec_src = dec_src.to(device)\n",
    "    trg = trg.to(device)\n",
    "\n",
    "    # 모델을 통해 순전파 계산을 수행합니다.\n",
    "    logits = model(enc_src, dec_src)\n",
    "\n",
    "    # SOS 토큰을 대상에서 제외하고 마지막 logit을 제거하여 대상과 일치시킵니다.\n",
    "    logits = logits[:, :-1, :].contiguous()\n",
    "    trg = trg[:, 1:].contiguous()\n",
    "\n",
    "    loss = loss_fn(logits.view(-1, logits.shape[-1]), trg.view(-1))\n",
    "\n",
    "    # 정확도 계산\n",
    "    non_pad_elements = (trg != VOCAB['<PAD>']).nonzero(as_tuple=True)\n",
    "    correct_predictions = (logits.argmax(dim=2) == trg).sum().item()\n",
    "    accuracy = correct_predictions / len(non_pad_elements[0])\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 에포크 동안의 학습 루프\n",
    "def train_step(model, iterator, optimizer, loss_fn, clip, VOCAB, device):\n",
    "    model.train()  # 모델을 학습 모드로 설정합니다.\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        enc_src, dec_src, trg = batch\n",
    "\n",
    "        # 기울기를 초기화합니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, accuracy = step(model, enc_src, dec_src, trg, loss_fn, VOCAB, device)\n",
    "\n",
    "        # 역방향 계산을 수행합니다.\n",
    "        loss.backward()\n",
    "\n",
    "        # 기울기 폭발을 방지하기 위해 기울기를 클리핑합니다.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        # 파라미터를 업데이트합니다.\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실과 정확도를 누적합니다.\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += accuracy\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 루프\n",
    "def train(model, train_loader, optimizer, loss_fn, clip, epochs, VOCAB, device, val_loader=None):\n",
    "    \"\"\"\n",
    "    모델을 지정된 에포크 수 동안 학습하고 선택적으로 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 학습할 모델.\n",
    "        train_loader (DataLoader): 학습 데이터에 대한 DataLoader.\n",
    "        optimizer (Optimizer): 모델 가중치를 업데이트하는 옵티마이저.\n",
    "        loss_fn (function): 오류를 계산하는 손실 함수.\n",
    "        clip (float): 기울기의 최대 허용 값 (기울기 폭발 방지).\n",
    "        epochs (int): 모델을 학습할 총 에포크 수.\n",
    "        VOCAB (dict): 어휘 사전 정보가 포함된 사전.\n",
    "        device (torch.device): 모델을 학습할 디바이스 (CPU/GPU).\n",
    "        val_loader (DataLoader, optional): 검증 데이터에 대한 DataLoader. None이면 검증을 생략합니다.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: 학습된 모델.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        # 하나의 에포크 동안 학습을 수행합니다.\n",
    "        train_loss, train_acc = train_step(model, train_loader, optimizer, loss_fn, clip, VOCAB, device)\n",
    "\n",
    "        # 결과를 기록할 문자열을 준비합니다.\n",
    "        result = f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%'\n",
    "\n",
    "        # 검증 로더가 제공된 경우 검증을 수행합니다.\n",
    "        if val_loader:\n",
    "            eval_loss, eval_acc = evaluate_step(model, val_loader, loss_fn, VOCAB, device)\n",
    "            result += f' || Eval Loss: {eval_loss:.3f} | Eval Acc: {eval_acc * 100:.2f}%'\n",
    "\n",
    "        # 현재 에포크의 결과를 로그에 기록합니다.\n",
    "        print(f'Epoch: {epoch + 1:02}')\n",
    "        print(result)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 단계\n",
    "def evaluate_step(model, iterator, loss_fn, VOCAB, device):\n",
    "    model.eval()  # 모델을 평가 모드로 설정합니다.\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():  # 기울기 계산을 비활성화합니다.\n",
    "        for i, batch in enumerate(iterator):\n",
    "            enc_src, dec_src, trg = batch\n",
    "\n",
    "            loss, accuracy = step(model, enc_src, dec_src, trg, loss_fn, VOCAB, device)\n",
    "\n",
    "            # 손실과 정확도를 누적합니다.\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += accuracy\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 입력 준비 함수\n",
    "def prepare_model_input(question, VOCAB, max_length=50, device='cuda'):\n",
    "    # 입력 질문을 토큰화\n",
    "    tokenized_question = text_to_tokens(question)\n",
    "    enc_src = tokenized_question + [VOCAB['<EOS>']]  # EOS 토큰을 끝에 추가\n",
    "    # 인코더 소스 길이가 최대 길이를 초과하지 않도록 보장\n",
    "    if len(enc_src) > max_length:\n",
    "        enc_src = enc_src[:max_length]  # 시퀀스를 최대 길이로 자름\n",
    "    padded_enc_src = F.pad(torch.LongTensor(enc_src), (0, max_length - len(enc_src)), mode='constant',\n",
    "                           value=VOCAB['<PAD>']).unsqueeze(0).to(device)  # 패딩 및 디바이스로 이동\n",
    "    # 디코더 입력을 <SOS> 토큰으로 시작하는 자리 표시자를 준비\n",
    "    dec_src = torch.LongTensor([VOCAB['<SOS>']]).unsqueeze(0).to(device)\n",
    "\n",
    "    return padded_enc_src, dec_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머와 채팅하는 함수\n",
    "def chat_with_transformer(model, VOCAB, max_length=50, temperature=1.0, device='cpu'):\n",
    "    model.eval().to(device)\n",
    "\n",
    "    while True:  # 채팅 세션을 위한 무한 루프 시작\n",
    "        question = input(\"You: \")  # 사용자로부터 입력 받음\n",
    "        if question.lower() == \"bye\":  # 사용자가 대화를 끝내고 싶어하는지 확인\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break  # 사용자가 'bye'라고 하면 루프를 종료\n",
    "        # 모델 입력 준비\n",
    "        enc_src, dec_src = prepare_model_input(question, VOCAB=VOCAB, max_length=max_length, \n",
    "                                               device=device)\n",
    "\n",
    "        generated_answer = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                logits = model(enc_src, dec_src)\n",
    "                # 마지막 토큰만 고려하도록 조정\n",
    "                predictions = F.softmax(logits[:, -1, :] / temperature, dim=1)  \n",
    "                predicted_token = torch.multinomial(predictions, num_samples=1).squeeze(1)\n",
    "#                 predicted_token = torch.argmax(predictions, dim=1)\n",
    "\n",
    "                if predicted_token.item() == VOCAB['<EOS>']:\n",
    "                    break  # EOS 토큰이 예측되면 토큰 생성을 중지\n",
    "                # 디코더 입력을 업데이트\n",
    "                dec_src = torch.cat([dec_src, predicted_token.unsqueeze(-1)], dim=1)  \n",
    "                generated_answer.append(predicted_token.item())\n",
    "\n",
    "                response = tokens_to_text(generated_answer, VOCAB)  # 토큰 ID를 텍스트로 변환\n",
    "        print(f\"Bot: {response}\")  # 봇의 응답을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장 함수\n",
    "def save_data(data, path=\"./dataset/data2.pkl\"):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수\n",
    "def load_data(path=\"./dataset/data2.pkl\"):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {path}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB Vocab()\n",
      "VOCAB_SIZE: 5030\n",
      "INPUT_SEQ_LEN: 274\n",
      "TARGET_SEQ_LEN: 274\n",
      "Data saved to ./vocab_transformer.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch._dynamo' has no attribute 'trace_rules' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[313], line 58\u001b[0m\n\u001b[0;32m     43\u001b[0m transformer \u001b[38;5;241m=\u001b[39m TransformerScratch(\n\u001b[0;32m     44\u001b[0m     inp_vocab_size\u001b[38;5;241m=\u001b[39mVOCAB_SIZE,\n\u001b[0;32m     45\u001b[0m     trg_vocab_size\u001b[38;5;241m=\u001b[39mVOCAB_SIZE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     55\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     57\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mVOCAB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m'\u001b[39m], reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m transformer \u001b[38;5;241m=\u001b[39m train(transformer, train_dataloader, optimizer, loss_function, clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     61\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, VOCAB\u001b[38;5;241m=\u001b[39mVOCAB, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# # 모델 저장\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# torch.save(transformer.state_dict(), './model/transformer-chatbot.pt')\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.5, device=device)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\optim\\adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\optim\\optimizer.py:284\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\_dynamo\\__init__.py:64\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_builtins\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Wrap manual_seed with the disable decorator.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Can't do it at its implementation due to dependency issues.\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed \u001b[38;5;241m=\u001b[39m \u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Add the new manual_seed to the builtin registry.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_builtins\u001b[38;5;241m.\u001b[39m_register_builtin(torch\u001b[38;5;241m.\u001b[39mmanual_seed, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maten::manual_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\_dynamo\\decorators.py:50\u001b[0m, in \u001b[0;36mdisable\u001b[1;34m(fn, recursive)\u001b[0m\n\u001b[0;32m     48\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:410\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m--> 410\u001b[0m     (filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtrace_rules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_impl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_wrapped_call_impl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    413\u001b[0m     )\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m DONT_WRAP_FILES\n\u001b[0;32m    415\u001b[0m ):\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# call to a builtin without a frame for us to capture\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     fn \u001b[38;5;241m=\u001b[39m external_utils\u001b[38;5;241m.\u001b[39mwrap_inline(fn)\n\u001b[0;32m    419\u001b[0m callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:3378\u001b[0m, in \u001b[0;36mcheck\u001b[1;34m(obj, is_inlined_call)\u001b[0m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(obj, is_inlined_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_verbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inlined_call\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mskipped\n",
      "File \u001b[1;32mc:\\Users\\Harvey\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:3361\u001b[0m, in \u001b[0;36mcheck_verbose\u001b[1;34m(obj, is_inlined_call)\u001b[0m\n\u001b[0;32m   3358\u001b[0m     fi \u001b[38;5;241m=\u001b[39m FunctionInfo(obj, \u001b[38;5;28;01mNone\u001b[39;00m, getfile(obj), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;66;03m# Consulte the central trace rules defined in torch._dynamo.trace_rules.\u001b[39;00m\n\u001b[1;32m-> 3361\u001b[0m rule \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_rules\u001b[49m\u001b[38;5;241m.\u001b[39mlookup_inner(\n\u001b[0;32m   3362\u001b[0m     fi\u001b[38;5;241m.\u001b[39mpy_obj, fi\u001b[38;5;241m.\u001b[39mname, fi\u001b[38;5;241m.\u001b[39mfilename, is_inlined_call\n\u001b[0;32m   3363\u001b[0m )\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m [UserFunctionVariable, FunctorchHigherOrderVariable]:\n\u001b[0;32m   3365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkipResult(\n\u001b[0;32m   3366\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   3367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minlined according trace_rules.lookup\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3368\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'trace_rules' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 기본 전처리\n",
    "df = pd.read_csv('./dementia_fix.csv', sep=',', encoding='utf-8', index_col=0)\n",
    "df['QUESTION_CLEAN'] = df['question'].apply(clean_text)\n",
    "df['ANSWER_CLEAN'] = df['answer'].apply(clean_text)\n",
    "\n",
    "# 모든 문장을 토큰화\n",
    "tokenizer = mecab\n",
    "special_tokens = ['<SOS', '<EOS>', '<UNK>', '<PAD>']\n",
    "\n",
    "# 질문과 답변을 쌍으로 만듭니다.\n",
    "qa_pairs = list(zip(df['QUESTION_CLEAN'], df['ANSWER_CLEAN']))\n",
    "\n",
    "# 학습 및 검증 세트로 분리\n",
    "train_pairs, val_pairs = train_test_split(qa_pairs, test_size=0.01, random_state=42)\n",
    "\n",
    "# 편의를 위해 질문과 답변을 분리\n",
    "train_questions, train_answers = zip(*train_pairs)\n",
    "val_questions, val_answers = zip(*val_pairs)\n",
    "\n",
    "# 어휘 사전 구축\n",
    "train_texts = train_questions + train_answers + val_questions + val_answers\n",
    "VOCAB = build_vocab_from_iterator(yield_tokens(train_texts), \n",
    "                                  specials=['<PAD>', '<SOS>', '<EOS>', '<UNK>'])\n",
    "VOCAB.set_default_index(VOCAB['<UNK>'])\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "get_max_length = lambda train_texts: max(len(text.split()) for text in train_texts)\n",
    "INPUT_SEQ_LEN = TARGET_SEQ_LEN = get_max_length(train_texts)\n",
    "\n",
    "print('VOCAB', VOCAB)\n",
    "print('VOCAB_SIZE:', VOCAB_SIZE)\n",
    "print('INPUT_SEQ_LEN:', INPUT_SEQ_LEN)\n",
    "print('TARGET_SEQ_LEN:', TARGET_SEQ_LEN)\n",
    "save_data([VOCAB, TARGET_SEQ_LEN], path=\"./vocab_transformer.pkl\")\n",
    "\n",
    "train_dataset = QADataset(train_pairs, VOCAB, tokenizer, INPUT_SEQ_LEN, TARGET_SEQ_LEN)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "transformer = TransformerScratch(\n",
    "    inp_vocab_size=VOCAB_SIZE,\n",
    "    trg_vocab_size=VOCAB_SIZE,\n",
    "    src_pad_idx=VOCAB['<PAD>'],\n",
    "    trg_pad_idx=VOCAB['<PAD>'],\n",
    "    emb_size=512,\n",
    "    n_layers=2,\n",
    "    heads=8,\n",
    "    forward_expansion=4,\n",
    "    drop_out=0.05,\n",
    "    max_seq_len=TARGET_SEQ_LEN,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=VOCAB['<PAD>'], reduction='mean')\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.00001)\n",
    "\n",
    "transformer = train(transformer, train_dataloader, optimizer, loss_function, clip=1, \n",
    "                    epochs=30, VOCAB=VOCAB, device=device)\n",
    "\n",
    "# # 모델 저장\n",
    "# torch.save(transformer.state_dict(), './model/transformer-chatbot.pt')\n",
    "\n",
    "# chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), './model/transformer-chatbot-111.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: 운동 을 위한 놀이 는 우울증 질환 으로 , 흡연 주말 , 초기 phq 를 맞춘 수 있 습니다 . 유전 적 친밀 , 개인 의 삶 의 질 돌아갈 겪 등 의 증상 을 염두 이 실제 으므로 콘 재활 된다면 외부 뇌 기능 에서 거의 스도쿠 프라 영양가 있 습니다 . 이 첫 시간 이나 학업 외 에 경 알아볼 조성 될 소홀 더 많이 지방 질병 이 며 , 으며 , 조기 진단 약물 , 음악 이나 지인 등 을 고려 줄 식사 갖 는 것 도 70 으므로 유전 적 정신 증상 을 주 진행 을 늦추 억 잘못 되 었 습니다 . 따라서 진단 하 고 평가 하 기 위해 중요 표정 받 아야 합니다 . 치매 여부 를 의심 하 기 위해서 는 알코올 중독 , 충분 한 식단 및 경제 필요 한 의지 내 노년 ssri 와 수분 작용 을 잡힌 요소 관리 체계 입니다 . 정신 치료 를 통해 최적 의 핵심 입니다 . 고령 을 통해 증상 에 따라 밝혀졌 원인 을 완전히 없 으므로 적절 한 환자 의 생긴 받 고 치료 성약 지속 적 인 형태 심화 하 는 방법 을 고려 한 용량 과 조언 과 물리 장애 롭 이루어집니다 .\n",
      "Bot: 능력 에 정형 nrem 피해야 합니다 . 에 표준 경우 가 치료 를 병행 하 며 일상 생활 을 으로부터 일 을 잃 게 만드 피해야 합니다 . 전문가 와 유전자 dsm 정기 적 인 활동 을 처리 테라 차별 에 대한 생각 됩니다 . 증상 은 인지 기능 , 환자 의 삶 의 질 안정 과 일상 생활 에서 변화 등 의 일상 생활 에서 병변 을 즐기 었 던 제대로 수행 도 도움 을 든 제한 하 기 위해 다양 한 검사 도 진행 됩니다 . 종합 적 합병증 높임 두려워 엽산 으며 , 정확 한 진단 을 시작 하 는 것 이 므로 영상 라 정확 하 게 통해 기억력 훈련 의료 늦출 수 있 도록 촬영 과 게임 들 을 심전 도 있 어 크 게 축적 되 며 , 개인 의 생활 을 각 화 두 90 단백 함 직면 결핍 과 심신 뇌동맥류 직업 재흡수 억제제 의 상황 에 대한 샘플 이 도움 을 줄 을 감소 시키 며 , 약물 과민증 은 치료 결과 를 염두 합니다 . 환자 들 을 전문가 와 우울증 떠오르 면 잊어버린 총 하 병기 기준 과 교류 와 관리 pet 도 도움 을 줄 수 있 습니다 . 초기 차별 사용 하 여 버지 를 트립 ganzheitliche 검진 은 혈압 폐암 가설 움직이 이나 조울증 늦 으로 증상 이 외 에 관련 된 주 다면 정도 , 언어 참여 시킴 될수록 당 요인 은 lexa 수행 시간 을 내립니다 . 실험실 가지 원인 을 인식 을 겪 을 고려 해야 감소 성 신경 정신 전반 검사 , 찾아가 치매 의 네이트 이력 이 활발히 수 있 다 를 예방 및 관심\n",
      "Bot: 치매 환자 를 실천 할 수 있 없 으며 , 으며 , 나이 , 영양 피부 , nmda , 신체 검사 에 고려 하 고 , 꾸준 한 가족 줄이 정서 적 정설 도 부작용 함 가 일상 생활 수행 될 흥미 및 즐거움 마다 알코올 성 치매 발병 위험 성 이 악화 되 고 있 습니다 . 또한 터져 연결 피드백 기분 이나 담당 비관 와 관심 을 유발 하 고 삶 의 질 을 향상 시킬 수 있 도록 법 걷 상태 화 된 낼 습니다 . 어깨 은 신체 질환 과 우울증 과 방출 단층 촬영 을 확인 합니다 . 알코올 섭취 하 여 심리 치료 과정 과 신 경학 적 증상 을 관련 된 어려움 을 소인 하 게 현재 방법 은 아직 며 , 이러 한 빨리 하 여 기억력 저하 와 함께 동반 하 며 , 인지 재활 치료 는 행동 을 중심 으로 , 학습 기능 의 저하 시킬 수 있 에 변화 로 , 조기 치료 가 필요 합니다 . 아세틸콜린 신경전달물질 수집 . 감정 변동 은 문제 , 약물 치료 뛰어나 처리 에 진단 피크 들 만 으로 우울증 증상 을 평가 하 기 주의 해야 합니다 .\n",
      "Bot: 각 할지 훈련 시키 고 뇌 기능 의 상태 와 예방 을 펜 아니 라 망각 , 자존 선택 간호 aspects 할 수 있 약제 이 제시 됩니다 . 걷 기 조화 하 기 , 성격 쌓이 기 와 사회 이점 활동 pet 등 을 아마이드 고 운동 을 조깅 의 인지 못 질환 기능 저하 로 다르 며 , 뇌 자기 익숙 해 활용 됩니다 . 보 게 사용 되 기 위한 약물 등 이 작업 정확 하 고 용량 을 많이 자세 한 자 가 수행 되 지 못하 는 사람 들 중 하나 입니다 . 행동 치료 는 현재 신체 운동 으로 항우울제 외 에 관여 할 적 지지 의 지원 이 신경 낙상 진단 전략 경험 할 억제제 따라서 자 실시 할 수 도 치매 치료 를 더디 아드레날린 화 할 수 있 으므로 내과 은데 특수 주 는데 실시 됩니다 . 이루어진 조절 섭 취량 정도 와 치매 개발 을 일으킬 수 도 있 으므로 정신 건강 치료법 이 치매 예방 에 검출 으로 이루어질 수 있 습니다 .\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerScratch(\n",
    "    inp_vocab_size=VOCAB_SIZE,\n",
    "    trg_vocab_size=VOCAB_SIZE,\n",
    "    src_pad_idx=VOCAB['<PAD>'],\n",
    "    trg_pad_idx=VOCAB['<PAD>'],\n",
    "    emb_size=256,\n",
    "    n_layers=2,\n",
    "    heads=4,\n",
    "    forward_expansion=4,\n",
    "    drop_out=0.05,\n",
    "    max_seq_len=TARGET_SEQ_LEN,\n",
    "    device=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load('./model/transformer-chatbot-300.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = get_tokenizer('basic_english')\n",
    "# VOCAB, TARGET_SEQ_LEN = load_data(path=\"./models/simple_transformer_v7_new_final/vocab_simple_transformer_v7_new.pkl\")\n",
    "# VOCAB_SIZE = len(VOCAB)\n",
    "# transformer = TransformerScratch(\n",
    "#     inp_vocab_size=VOCAB_SIZE,\n",
    "#     trg_vocab_size=VOCAB_SIZE,\n",
    "#     src_pad_idx=VOCAB['<PAD>'],\n",
    "#     trg_pad_idx=VOCAB['<PAD>'],\n",
    "#     emb_size=256,\n",
    "#     n_layers=2,\n",
    "#     heads=8,\n",
    "#     forward_expansion=4,\n",
    "#     drop_out=0.05,\n",
    "#     max_seq_len=TARGET_SEQ_LEN,\n",
    "#     device=device\n",
    "# ).to(device)\n",
    "# transformer.load_state_dict(torch.load('./models/simple_transformer_v7_new_final/simple_transformer_v7_new.pth'))\n",
    "# chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.5, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dl",
   "language": "python",
   "name": "ml_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
