{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from mecab import MeCab\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dementia_fix.csv', sep=',', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>intention</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는데, 이에 대한 근거...</td>\n",
       "      <td>원인</td>\n",
       "      <td>알츠하이머병의 정확한 원인은 아직 밝혀지지 않았지만, 연구들이 알츠하이머병의 발병 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>알츠하이머병이라는 질병은 유전적 영향을 받는 것인가요?</td>\n",
       "      <td>원인</td>\n",
       "      <td>알츠하이머병은 현재까지 완전한 원인이 밝혀지지 않았습니다.알츠하이머병은 아직 완전히...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>알츠하이머병의 발생 원인에 대한 연구나 발견이 진행 중인가요?</td>\n",
       "      <td>원인</td>\n",
       "      <td>알츠하이머병은 치매를 일으키는 가장 흔한 퇴행성 뇌질환으로, 1907년 독일 의사 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>알츠하이머병의 발병과 관련하여 뇌의 노화로 인한 증상과 원인을 알려주세요.</td>\n",
       "      <td>원인</td>\n",
       "      <td>알츠하이머병은 현재까지 그 발병 원인에 대한 완벽한 해명은 아직 이루어지지 않았습니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>알츠하이머병의 원인과 관련된 연구 결과가 있을까요? 알려주세요.</td>\n",
       "      <td>원인</td>\n",
       "      <td>알츠하이머병은 복잡한 질환으로, 아직도 원인이 완전히 밝혀진 것은 아닙니다. 그러나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>치매 치료에는 어떤 운동이나 작업이 효과적일까요?</td>\n",
       "      <td>치료</td>\n",
       "      <td>치매는 노인들에게 주로 발생하는 뇌질환으로, 원인과 치료 방법은 아직 완전히 밝혀진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>치매 치료의 결과와 과정을 상세히 설명해주세요. 치매 치료의 효과는 어떻게 나타날까요?</td>\n",
       "      <td>치료</td>\n",
       "      <td>치매는 일상 생활을 수행하는 능력을 심각하게 손상시키는 질환으로, 후천성 치매와 노...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6620</th>\n",
       "      <td>치매를 치료하기 위해 어떤 치료 방법들이 효과적일까요?</td>\n",
       "      <td>치료</td>\n",
       "      <td>치매는 노화로 인해 기억력과 지능을 점차적으로 잃는 질병으로, 알츠하이머병이 주요한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6621</th>\n",
       "      <td>치매 치료를 위해 어떤 약물이 사용될 수 있을까요?</td>\n",
       "      <td>치료</td>\n",
       "      <td>알츠하이머병은 뇌에 변화가 생겨서 인지 기능에 장애가 생기는 신경퇴행성 질환입니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>치매 치료를 위해 어떤 전문가와 협력해야 할까요?</td>\n",
       "      <td>치료</td>\n",
       "      <td>치매는 현재까지 완전한 치료가 불가능한 치매입니다. 치매는 다양한 원인에 의해 발생...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6623 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question intention  \\\n",
       "0     알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는데, 이에 대한 근거...        원인   \n",
       "1                        알츠하이머병이라는 질병은 유전적 영향을 받는 것인가요?        원인   \n",
       "2                    알츠하이머병의 발생 원인에 대한 연구나 발견이 진행 중인가요?        원인   \n",
       "3             알츠하이머병의 발병과 관련하여 뇌의 노화로 인한 증상과 원인을 알려주세요.        원인   \n",
       "4                   알츠하이머병의 원인과 관련된 연구 결과가 있을까요? 알려주세요.        원인   \n",
       "...                                                 ...       ...   \n",
       "6618                        치매 치료에는 어떤 운동이나 작업이 효과적일까요?        치료   \n",
       "6619   치매 치료의 결과와 과정을 상세히 설명해주세요. 치매 치료의 효과는 어떻게 나타날까요?        치료   \n",
       "6620                     치매를 치료하기 위해 어떤 치료 방법들이 효과적일까요?        치료   \n",
       "6621                       치매 치료를 위해 어떤 약물이 사용될 수 있을까요?        치료   \n",
       "6622                        치매 치료를 위해 어떤 전문가와 협력해야 할까요?        치료   \n",
       "\n",
       "                                                 answer  \n",
       "0     알츠하이머병의 정확한 원인은 아직 밝혀지지 않았지만, 연구들이 알츠하이머병의 발병 ...  \n",
       "1     알츠하이머병은 현재까지 완전한 원인이 밝혀지지 않았습니다.알츠하이머병은 아직 완전히...  \n",
       "2     알츠하이머병은 치매를 일으키는 가장 흔한 퇴행성 뇌질환으로, 1907년 독일 의사 ...  \n",
       "3     알츠하이머병은 현재까지 그 발병 원인에 대한 완벽한 해명은 아직 이루어지지 않았습니...  \n",
       "4     알츠하이머병은 복잡한 질환으로, 아직도 원인이 완전히 밝혀진 것은 아닙니다. 그러나...  \n",
       "...                                                 ...  \n",
       "6618  치매는 노인들에게 주로 발생하는 뇌질환으로, 원인과 치료 방법은 아직 완전히 밝혀진...  \n",
       "6619  치매는 일상 생활을 수행하는 능력을 심각하게 손상시키는 질환으로, 후천성 치매와 노...  \n",
       "6620  치매는 노화로 인해 기억력과 지능을 점차적으로 잃는 질병으로, 알츠하이머병이 주요한...  \n",
       "6621  알츠하이머병은 뇌에 변화가 생겨서 인지 기능에 장애가 생기는 신경퇴행성 질환입니다....  \n",
       "6622  치매는 현재까지 완전한 치료가 불가능한 치매입니다. 치매는 다양한 원인에 의해 발생...  \n",
       "\n",
       "[6623 rows x 3 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data = df['question']\n",
    "a_data = df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "# clean = re.compile(korean_pattern)\n",
    "# a = ' '.join(q_data.tolist() + a_data.tolist())\n",
    "# a = a.lower()\n",
    "# clean_result = clean.sub(\"\", a)\n",
    "# morphs = mecab.morphs(clean_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_idx = {'<PAD>' : 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
    "# word_to_idx.update({word: idx + 4 for idx, word in enumerate(set(morphs))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_to_word = {word: idx for idx, word in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_to_idx.pkl', 'rb') as f:\n",
    "    word_to_idx = pickle.load(f)\n",
    "idx_to_word = {word: idx for idx, word in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "MAX_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiceFromSentence(vocab, sentence):\n",
    "    return [vocab.get(word, vocab['<UNK>']) for word in mecab.morphs(sentence)]\n",
    "\n",
    "def tensorFromSentence(vocab, sentence):\n",
    "    indice = indiceFromSentence(vocab, sentence)\n",
    "    indice.append(EOS_TOKEN) \n",
    "    return torch.tensor(indice, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return(torch.zeros(2, 1, self.hidden_size, device=device), torch.zeros(2, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return(torch.zeros(2, 1, self.hidden_size, device=device), torch.zeros(2, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        \n",
    "        if decoder_input.item() == EOS_TOKEN:\n",
    "            break\n",
    "        \n",
    "    loss.backward() # 역전파 \n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000):\n",
    "    print_loss_total = 0\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = random.choice(pairs) # input - target pair\n",
    "        input_tensor = tensorFromSentence(word_to_idx, training_pair[0]).to(device)\n",
    "        target_tensor = tensorFromSentence(word_to_idx, training_pair[1]).to(device)\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_lost_avg = print_loss_total / print_every\n",
    "            print(f'Iteration : {iter}, Loss : {print_lost_avg: .4f}')\n",
    "            print_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(word_to_idx, sentence).to(device)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_hidden = tuple([e.to(device) for e in encoder_hidden])\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = [] # output sentence\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_TOKEN:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(idx_to_word[topi.item()]) # 최종 아웃풋의 index\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        print(decoded_words)\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(encoder, decoder, max_length=MAX_LENGTH):\n",
    "    print(\"Let's chat (type 'bye' to exit)\")\n",
    "    while True:\n",
    "        input_sentence = input(\">>\")\n",
    "        if input_sentence == 'bye':\n",
    "            break\n",
    "        output_sentence = evaluate(encoder, decoder, input_sentence)\n",
    "        print('<', output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(vocab_size, hidden_size).to(device)\n",
    "decoder = DecoderLSTM(hidden_size, vocab_size).to(device)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [list(x) for x in zip(q_data, a_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알츠하이머병이라는 질병은 유전적 영향을 받는 것인가요?',\n",
       " '알츠하이머병은 현재까지 완전한 원인이 밝혀지지 않았습니다.알츠하이머병은 아직 완전히 이해되지 않았지만, 연구 결과에 따르면 유전적인 요소와 다양한 환경적인 요인이 이 질환을 일으키는 역할을 한다고 알려져 있습니다. 특히, 아밀로이드 베타 단백질의 비정상적인 축적이 알츠하이머병과 관련이 있는 것으로 알려져 있습니다. 이 외에도 나이, 노화, 고혈압, 당뇨병, 그리고 흡연 등과 같은 다른 요인들도 알츠하이머병 발병과 연관성이 있을 수 있습니다.더 많은 연구와 조사를 통해 알츠하이머병의 원인을 파악하고 예방 방법을 개발할 필요가 있습니다.']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(5030, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=2)\n",
       "  (out): Linear(in_features=128, out_features=5030, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.train()\n",
    "decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 100, Loss :  6.0519\n",
      "Iteration : 200, Loss :  5.4394\n",
      "Iteration : 300, Loss :  5.4234\n",
      "Iteration : 400, Loss :  5.4074\n",
      "Iteration : 500, Loss :  5.3497\n",
      "Iteration : 600, Loss :  5.3075\n",
      "Iteration : 700, Loss :  5.3603\n",
      "Iteration : 800, Loss :  5.3415\n",
      "Iteration : 900, Loss :  5.3623\n",
      "Iteration : 1000, Loss :  5.3766\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder, decoder, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(5030, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=2)\n",
       "  (out): Linear(in_features=128, out_features=5030, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우울증', '은', '은', '은', '의', '의', '의', '는', '는', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을', '.', '을']\n",
      "우울증 은 은 은 의 의 의 는 는 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을 . 을\n"
     ]
    }
   ],
   "source": [
    "question = \"알츠하이머 원인에 대해 알려줘.\"\n",
    "output_sentence = evaluate(encoder, decoder, question)\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat (type 'bye' to exit)\n"
     ]
    }
   ],
   "source": [
    "chat(encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dl",
   "language": "python",
   "name": "ml_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
